---
name: dnaspec-context-optimization
description: Optimize context to prevent explosion and corruption while maintaining appropriate complexity. Balance clarity, relevance, and completeness against context size limits. When you need to prevent context explosion, fix context corruption, or optimize for appropriate complexity, use this skill. Works with context-analysis in a continuous improvement cycle.
---

# DNASPEC Context Optimization

## 使用时机

当用户提到以下需求时，使用此技能：
- "优化上下文" 或 "optimize context"
- "上下文爆炸" 或 "context explosion"
- "上下文腐化" 或 "context corruption"
- "适当复杂度" 或 "appropriate complexity"
- "提高清晰度" 或 "improve clarity"
- "增强相关性" 或 "enhance relevance"
- "补充完整性" 或 "improve completeness"
- "精简内容" 或 "make concise"
- "统一表述" 或 "ensure consistency"
- 需要预防上下文爆炸
- 需要修复上下文腐化

**不要在以下情况使用**：
- ❌ 初始上下文分析（使用context-analysis技能）
- ❌ 一般文档编辑
- ❌ 代码重构

## 核心理念

### 🎯 预防上下文爆炸和腐化

**什么是上下文爆炸？**

上下文爆炸是指上下文大小不受控制地增长，导致：
- 🚫 响应时间显著增加
- 🚫 处理成本急剧上升
- 🚫 信息密度下降
- 🚫 AI注意力分散
- 🚫 质量明显下降

**什么是上下文腐化？**

上下文腐化是指上下文质量逐渐恶化：
- 🚫 冗余信息累积
- 🚫 过时信息未清理
- 🚫 逻辑不一致
- 🚫 结构混乱
- 🚫 关键信息被淹没

**预防机制**：

```
context-analysis 发现问题
    ↓
context-optimization 解决问题
    ↓
持续监控
    ↓
循环改进
```

### 🎯 适当复杂度（Appropriate Complexity）

**不是越简单越好，也不是越复杂越好**

**❌ 过度简化**：
```
"系统处理数据"
→ 太简单，丢失关键信息
→ 无法指导实现
→ 上下文利用率低
```

**❌ 过度复杂**：
```
"系统是一个基于微服务架构的分布式数据处理平台，采用事件驱动架构模式，通过消息队列实现异步通信，..."
→ 太复杂，增加上下文负担
→ 包含不必要的技术细节
→ 上下文利用率低
```

**✅ 适当复杂度**：
```
"系统采用微服务架构处理数据，包括：
- 数据采集服务：从多个数据源收集数据
- 数据处理服务：转换和验证数据
- 数据存储服务：持久化处理结果"
→ 复杂度适中
→ 包含必要信息
→ 上下文效率高
```

**适当复杂度的原则**：
- ✅ **信息完整** - 包含所有必要信息
- ✅ **表达清晰** - 容易理解
- ✅ **结构合理** - 逻辑清晰
- ✅ **大小适中** - 在token限制内

### 🎯 与context-analysis的配合

**循环改进流程**：

```
第一步：context-analysis 分析
    ↓
输出质量报告：
{
  "clarity": 0.65,      # 需要改进
  "relevance": 0.75,    # 可接受
  "completeness": 0.70, # 需要改进
  "consistency": 0.88,  # 良好
  "efficiency": 0.50    # 需要紧急改进
}
    ↓
第二步：context-optimization 优化
    ↓
针对低分维度优化：
- clarity: 0.65 → 0.85
- completeness: 0.70 → 0.82
- efficiency: 0.50 → 0.90
    ↓
第三步：context-analysis 再次分析
    ↓
验证改进效果，确保：
✅ 没有引入新问题
✅ 上下文大小在限制内
✅ 质量全面提升
```

**配合策略**：

**analysis 发现问题** → **optimization 解决问题**

```yaml
analysis:
  识别问题:
    - 上下文过大 (100k tokens)
    - 信息密度低
    - 存在冗余

optimization:
  解决问题:
    - 删除冗余信息
    - 精简表达
    - 提高信息密度

result:
  优化后:
    - 上下文大小 (20k tokens)
    - 信息密度高
    - 无冗余
```

---

## 全生命周期应用

### 📋 Idea阶段：防止概念过度复杂化

**场景**：用户有一个模糊的想法，需要保持概念的清晰和简洁

**示例**：
```
用户想法："我想做一个AI系统，能够理解自然语言，
          然后进行深度学习分析，再用机器学习模型
          处理，最后通过神经网络输出结果"

问题分析：
❌ 术语冗余：深度学习、机器学习、神经网络（重复概念）
❌ 结构混乱：没有清晰的流程
❌ 信息密度低：用了太多词说一件事

优化后：
"我想构建一个自然语言处理系统：
- 输入：自然语言文本
- 处理：使用深度学习模型分析
- 输出：结构化的分析结果"

改进：
✅ 删除重复术语
✅ 结构清晰（输入-处理-输出）
✅ 信息密度高
✅ 防止上下文爆炸
```

**使用技能**：
```
/dnaspec.context-optimization "自然语言处理系统概念"
→ 保持核心概念
→ 删除冗余术语
→ 提高信息密度
→ 防止后续上下文膨胀
```

### 📋 需求阶段：确保需求文档的质量

**场景**：有完整的需求文档，需要优化质量和大小

**示例**：
```
需求文档（优化前）：
"用户认证系统应该具备以下功能：
首先，用户能够进行注册操作，通过填写用户名、
密码、邮箱等信息来创建账户。其次，用户能够进行
登录操作，通过输入用户名和密码来访问系统。
此外，系统还应该提供密码重置功能，当用户忘记
密码时，可以通过邮箱重置。最后，系统应该提供
用户信息管理功能，用户可以修改自己的个人信息。"

问题分析：
❌ 啰嗦重复：多次提到"用户"、"功能"
❌ 结构混乱：没有清晰的分类
❌ 信息密度低：500+ tokens，实际信息有限

优化后：
"用户认证系统功能需求：

1. 用户注册
   - 输入：用户名、密码、邮箱
   - 输出：创建账户

2. 用户登录
   - 输入：用户名/邮箱、密码
   - 输出：访问令牌

3. 密码重置
   - 触发：用户忘记密码
   - 方式：邮箱验证
   - 输出：新密码

4. 信息管理
   - 操作：修改个人信息
   - 验证：需要登录"

改进：
✅ 结构清晰（分点列举）
✅ 信息密度高（300 tokens）
✅ 易于理解和维护
✅ 防止上下文膨胀
```

### 📋 细化阶段：控制详细设计的复杂度

**场景**：功能实现过程中，需要控制技术细节的复杂度

**示例**：
```
技术设计（优化前）：
"支付处理系统采用微服务架构，使用Spring Cloud
框架实现服务注册与发现，通过Ribbon实现客户端
负载均衡，使用Hystrix实现服务熔断和降级，
采用Feign作为声明式HTTP客户端，使用Zuul作为
API网关，通过Spring Cloud Config实现配置
中心，使用Spring Cloud Stream实现消息驱动..."

问题分析：
❌ 技术栈罗列过度
❌ 没有说明为什么选择这些技术
❌ 上下文膨胀：800+ tokens，但核心信息有限
❌ 可能腐化：技术会过时

优化后：
"支付处理系统技术架构：

核心架构：微服务
目的：提高可扩展性和容错能力

关键组件：
1. API网关
   - 功能：统一入口、路由、认证
   - 技术：Zuul

2. 服务注册与发现
   - 功能：动态服务管理
   - 技术：Eureka

3. 负载均衡
   - 功能：流量分发
   - 技术：Ribbon

4. 容错机制
   - 功能：服务熔断、降级
   - 技术：Hystrix

配置管理：Spring Cloud Config
消息驱动：Spring Cloud Stream"

改进：
✅ 按功能分类，而非技术罗列
✅ 说明每个组件的目的
✅ 上下文精简（500 tokens）
✅ 防止腐化：技术变更时容易更新
```

### 📋 智能阶段：优化智能体上下文

**场景**：智能体执行任务时，需要优化其局部上下文

**示例**：
```
智能体上下文（优化前）：
"CodeReviewAgent负责审查代码，需要检查代码的
安全性、性能、可读性、可维护性等多个方面。
在安全性方面，需要检查SQL注入、XSS、CSRF等
常见安全漏洞。在性能方面，需要检查是否存在
性能瓶颈、资源泄漏等问题。在可读性方面，
需要检查代码风格、命名规范、注释质量等。
..."

问题分析：
❌ 啰嗦重复：多次提到"方面"、"检查"
❌ 分类不清晰：安全、性能、可读性混杂
❌ 上下文效率低：700 tokens，信息密度低

优化后：
"CodeReviewAgent 审查维度：

1. 安全性检查
   - SQL注入
   - XSS跨站脚本
   - CSRF跨站请求伪造
   - 硬编码密钥

2. 性能检查
   - 性能瓶颈（循环、递归）
   - 资源泄漏（内存、连接）
   - 不必要的计算

3. 代码质量
   - 代码风格（PEP8, Airbnb）
   - 命名规范
   - 注释完整性
   - 函数复杂度

4. 可维护性
   - 模块化程度
   - 耦合度
   - 重复代码

输出：审查报告（JSON格式）"

改进：
✅ 清晰分类
✅ 具体检查项
✅ 信息密度高（400 tokens）
✅ 易于智能体理解和执行
✅ 防止上下文爆炸
```

---

## 核心功能

### 1. 防止上下文爆炸

**爆炸原因识别**：

**原因1：冗余累积**
```
❌ 爆炸前：
段落1: "系统支持数据导入"
段落2: "系统可以导入数据"
段落3: "数据导入功能已实现"
段落4: "我们提供了数据导入能力"

✅ 优化后：
"系统支持数据导入功能"
```

**原因2：过度详细**
```
❌ 爆炸前：
"用户注册流程如下：首先，用户访问注册页面，
然后填写用户名字段，用户名必须是唯一的，
不能与其他用户重复，长度在4-20个字符之间。
接着填写密码字段，密码至少8个字符，
必须包含大小写字母和数字..."

✅ 优化后：
"用户注册流程：
1. 访问注册页面
2. 填写表单：
   - 用户名：4-20字符，唯一
   - 密码：8+字符，包含大小写和数字
   - 邮箱：有效邮箱地址
3. 提交注册"
```

**原因3：历史累积**
```
❌ 爆炸前：
"v1.0: 实现基础功能
v1.1: 添加用户认证
v1.2: 添加数据导入
v1.3: 改进用户界面
v1.4: 修复性能问题
v1.5: 添加导出功能
...（20个版本的详细变更记录）"

✅ 优化后：
"当前版本：v2.0
核心功能：
- 用户认证与授权
- 数据导入导出
- 数据分析与可视化

最近重大变更：
- v2.0: 重构数据架构
- v1.5: 添加导出功能"
```

**预防策略**：
```yaml
strategy:
  1. 定期清理:
     frequency: 每个版本
     actions:
       - 删除过时信息
       - 合并重复内容
       - 归档历史记录

  2. 信息分层:
     layers:
       - 核心信息: 必须保留
       - 详细信息: 按需加载
       - 历史信息: 归档存储

  3. 大小限制:
     hard_limit: 50k tokens
     soft_limit: 30k tokens
     action: 超过soft_limit时触发优化
```

### 2. 修复上下文腐化

**腐化类型识别**：

**类型1：信息不一致**
```
❌ 腐化：
"系统支持Python 3.8"
...
"推荐使用Python 3.6"

✅ 修复：
统一为："系统支持Python 3.8+"
```

**类型2：结构混乱**
```
❌ 腐化：
"# API接口
## 数据模型
### 错误处理
# 配置说明"

✅ 修复：
"# 系统文档
## API接口
## 数据模型
## 错误处理
## 配置说明"
```

**类型3：关键信息被淹没**
```
❌ 腐化：
"系统架构介绍（1000字）...
安装说明（500字）...
**重要：在开始使用前，请配置API密钥**...
使用示例（2000字）..."

✅ 修复：
"# 快速开始

## 前置要求
1. 配置API密钥（重要！）
2. 安装依赖

## 详细说明
- 系统架构
- 安装步骤
- 使用示例"
```

**修复策略**：
```yaml
restoration:
  1. 一致性检查:
     - 术语统一
     - 数据一致
     - 逻辑自洽

  2. 结构重组:
     - 重新组织章节
     - 建立层次关系
     - 突出关键信息

  3. 信息清理:
     - 删除过时内容
     - 移除重复信息
     - 归档历史数据
```

### 3. 优化到适当复杂度

**复杂度评估**：

**过低**：
```
"系统处理数据"
→ 信息不足
→ 无法实现
→ 需要补充
```

**适当**：
```
"系统采用ETL架构处理数据：
- Extract：从多个数据源提取数据
- Transform：清洗和转换数据格式
- Load：加载到目标数据库"
→ 信息完整
→ 结构清晰
→ 易于实现
```

**过高**：
```
"系统采用基于Kappa架构的实时流处理框架，
使用Apache Kafka作为消息队列，通过
Apache Flink进行流计算，利用Redis
作为缓存层，..."
→ 技术细节过多
→ 增加理解负担
→ 需要精简
```

**优化原则**：
```yaml
principles:
  1. 信息完整性:
     - 包含所有必要信息
     - 不过度简化

  2. 表达清晰性:
     - 使用准确术语
     - 提供必要解释
     - 结构逻辑清晰

  3. 大小适度性:
     - 在token限制内
     - 信息密度高
     - 无冗余内容

  4. 可维护性:
     - 易于更新
     - 结构化组织
     - 模块化设计
```

### 4. 优化目标维度

**1. 清晰度增强 (Clarity)**

**优化策略**：
- 用精确语言替换模糊术语
- 重构混乱的句子结构
- 在必要处添加解释说明
- 改善思路的逻辑流

**优化示例**：
```
原始内容：
> "这个东西应该能处理很多情况下的那个数据问题"

优化后：
> "该系统支持处理多种数据格式问题，
> 包括 CSV、JSON 和 XML"

改进点：
- ✅ 明确主体（"系统"而非"东西"）
- ✅ 具体化数据格式
- ✅ 清晰表达功能范围
```

**2. 相关性改进 (Relevance)**

**优化策略**：
- 删除离题信息
- 加强与主要观点的联系
- 添加支持目标的细节
- 重新聚焦核心主题

**优化示例**：
```
原始内容：
> "微服务架构将系统的不同功能拆分成独立的服务。
> 近年来，云计算发展迅速，AI技术也在不断进步。
> 我们的系统采用微服务架构，提高了可扩展性。"

优化后：
> "微服务架构将系统的不同功能拆分成独立的服务。
> 我们的系统采用微服务架构，实现了以下优势：
> - 提高系统可扩展性
> - 增强容错能力
> - 支持独立部署和升级"

改进点：
- ✅ 删除无关的云计算和AI内容
- ✅ 聚焦微服务架构的价值
- ✅ 添加与主题相关的具体优势
```

**3. 完整性增强 (Completeness)**

**优化策略**：
- 识别并填补信息空缺
- 添加缺失的背景或上下文
- 包含必要的细节或规范
- 确保所有必需元素都存在

**优化示例**：
```
原始内容：
> "安装完成后，运行服务即可"

优化后：
> "安装完成后，按以下步骤启动服务：
> 1. 检查配置文件是否正确（config/app.yaml）
> 2. 运行启动命令：`npm start`
> 3. 验证服务状态：访问 http://localhost:3000/health
> 4. 查看日志确认无错误信息"

改进点：
- ✅ 添加具体步骤
- ✅ 包含验证方法
- ✅ 提供故障排查信息
```

**4. 简洁度改进 (Conciseness)**

**优化策略**：
- 删除冗余内容
- 精简冗长的解释
- 消除不必要的重复
- 在保持原意的前提下缩短篇幅

**优化示例**：
```
原始内容：
> "在设计系统的时候，我们必须要考虑到各种不同的因素。
> 这些因素包括但不限于性能方面的问题、安全性方面的问题、
> 可扩展性方面的问题，以及维护性方面的问题。"

优化后：
> "系统设计需综合考虑性能、安全性、可扩展性和可维护性"

改进点：
- ✅ 删除重复表述
- ✅ 简化句子结构
- ✅ 保持核心信息完整
```

**5. 一致性增强 (Consistency)**

**优化策略**：
- 统一术语使用
- 解决矛盾陈述
- 确保章节间逻辑流畅
- 保持一致的语气和风格

**优化示例**：
```
原始内容：
> "用户可以使用 client 或 client-side 来访问 API。
> 在服务器端 server 端，使用后端接口。"

优化后：
> "客户端（client）可以通过 REST API 访问系统。
> 服务端（server）提供相应的接口实现。"

改进点：
- ✅ 统一使用"客户端"和"服务端"
- ✅ 一致的术语表达方式
- ✅ 统一的技术风格
```

---

## 优化流程

### 第一步：识别优化目标

使用 **context-analysis** 技能分析上下文：
```yaml
analysis_output:
  quality_scores:
    clarity: 0.65      # 需要改进
    relevance: 0.75    # 可接受
    completeness: 0.70 # 需要改进
    consistency: 0.88  # 良好
    efficiency: 0.50  # 需要紧急改进

  context_size:
    current: 45000 tokens
    limit: 50000 tokens
    status: 接近上限

  issues:
    - type: 冗余
      severity: high
    - type: 结构混乱
      severity: medium
```

### 第二步：确定优化策略

基于分析结果制定策略：
```yaml
optimization_strategy:
  primary_goals:
    - 防止上下文爆炸
    - 提高信息密度
    - 修复腐化

  specific_actions:
    1. 删除冗余信息：
       - 合并重复段落
       - 移除过时内容
       - 预计减少: 10000 tokens

    2. 提高清晰度：
       - 重写模糊描述
       - 添加必要解释
       - 预计提升: 20%

    3. 重组结构：
       - 建立清晰层次
       - 突出关键信息
       - 提升可维护性
```

### 第三步：应用优化

执行优化操作：
```yaml
execution:
  phase_1: 清理
    actions:
      - 删除冗余
      - 归档历史
      - 移除过时信息

  phase_2: 重组
    actions:
      - 重新组织章节
      - 建立层次结构
      - 突出关键信息

  phase_3: 精炼
    actions:
      - 提高清晰度
      - 增强完整性
      - 统一表述

  phase_4: 验证
    actions:
      - 检查信息完整性
      - 确认大小限制
      - 验证质量提升
```

### 第四步：验证优化效果

使用 **context-analysis** 再次分析：
```yaml
verification:
  before:
    clarity: 0.65
    completeness: 0.70
    efficiency: 0.50
    size: 45000 tokens

  after:
    clarity: 0.85 (+0.20)
    completeness: 0.82 (+0.12)
    efficiency: 0.90 (+0.40)
    size: 28000 tokens (-38%)

  preserved:
    - 所有核心概念
    - 关键技术细节
    - 重要决策依据
    - 必要背景信息
```

---

## 输出格式

```json
{
  "optimization_summary": {
    "primary_goal": "prevent_explosion",
    "original_length": 45000,
    "optimized_length": 28000,
    "reduction_ratio": 0.38,
    "explosion_prevented": true
  },
  "corruption_fixed": [
    {
      "type": "inconsistency",
      "description": "统一Python版本要求",
      "before": "Python 3.6/3.7/3.8",
      "after": "Python 3.8+"
    },
    {
      "type": "structure",
      "description": "重组混乱的章节",
      "before": "无序排列",
      "after": "按功能模块分类"
    }
  ],
  "quality_metrics": {
    "before": {
      "clarity": 0.65,
      "relevance": 0.75,
      "completeness": 0.70,
      "consistency": 0.88,
      "efficiency": 0.50
    },
    "after": {
      "clarity": 0.85,
      "relevance": 0.88,
      "completeness": 0.82,
      "consistency": 0.95,
      "efficiency": 0.90
    }
  },
  "improvements": {
    "clarity": "+0.20 (显著提升)",
    "efficiency": "+0.40 (大幅改善)",
    "explosion_risk": "high → low"
  },
  "complexity_assessment": {
    "before": "过高 - 包含过多技术细节",
    "after": "适当 - 信息完整且精简",
    "appropriate": true
  }
}
```

---

## 使用示例

### 示例 1：防止上下文爆炸

**输入**：
```
[冗长的API文档，包含50个端点的详细描述，
每个端点都有3-5个示例，总共15000个tokens]
```

**优化目标**：防止爆炸 + 保持完整性

**优化后**：
```
# API文档

## 核心端点（10个）
详细说明 + 1个示例

## 常用端点（20个）
简要说明 + 参数列表

## 其他端点（20个）
仅端点列表和基本功能

## 详细示例
单独的示例文件（按需加载）
```

**改进点**：
1. ✅ 上下文大小从15k降到8k (-47%)
2. ✅ 核心信息完整保留
3. ✅ 详细信息按需加载
4. ✅ 防止上下文爆炸
5. ✅ 提高信息密度

### 示例 2：修复上下文腐化

**输入**：
```
[一段混乱的技术文档，术语不一致，
结构混乱，关键信息被淹没在大量文字中]
```

**优化目标**：修复腐化 + 提高清晰度

**优化后**：
```
# 系统架构

## 核心组件
1. API网关
2. 服务层
3. 数据层

## 术语表
- 统一所有术语定义
- 避免歧义

## 快速参考
- 常见问题
- 关键配置
- 重要限制
```

**改进点**：
1. ✅ 结构清晰
2. ✅ 术语统一
3. ✅ 关键信息突出
4. ✅ 修复腐化
5. ✅ 易于维护

---

## 质量检查清单

### 优化效果检查

**防止爆炸检查**：
- [ ] 上下文大小在限制内
- [ ] 信息密度提升
- [ ] 冗余内容删除
- [ ] 无累积风险

**修复腐化检查**：
- [ ] 术语统一
- [ ] 结构清晰
- [ ] 逻辑一致
- [ ] 关键信息突出

**适当复杂度检查**：
- [ ] 信息完整
- [ ] 表达清晰
- [ ] 结构合理
- [ ] 大小适中

**质量提升检查**：
- [ ] 清晰度提升
- [ ] 相关性增强
- [ ] 完整性保持
- [ ] 一致性改善
- [ ] 效率提高

---

## 协作技能

- **dnaspec-context-analysis**: 分析上下文质量，识别问题
- **dnaspec-architect**: 整体架构协调
- **dnaspec-task-decomposer**: 任务分解优化

---

## 关键成就

1. ✅ **预防上下文爆炸** - 控制大小，防止无限增长
2. ✅ **修复上下文腐化** - 清理冗余，重组结构
3. ✅ **适当复杂度** - 找到信息完整的平衡点
4. ✅ **与analysis配合** - 循环改进，持续优化
5. ✅ **全生命周期应用** - Idea→需求→细化→智能四阶段
6. ✅ **信息密度优化** - 在有限空间内传递更多信息

---

*此技能专注于预防上下文爆炸和腐化，通过优化到适当复杂度，确保上下文在大小限制内保持高质量，与context-analysis形成循环改进机制。*
