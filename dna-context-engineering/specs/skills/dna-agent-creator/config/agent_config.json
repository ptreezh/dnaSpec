{
  "llm_config": {
    "provider": "ollama",
    "model": "llama3:latest",
    "default_temperature": 0.3,
    "max_tokens": 2048,
    "timeout": 30
  },
  "resource_allocation": {
    "cpu_limit": "0.5",
    "memory_limit": "1GB",
    "api_quota_per_hour": 500
  },
  "agent_types": {
    "security": {
      "llm_config": {
        "temperature": 0.1,
        "max_tokens": 1024
      },
      "resource_allocation": {
        "priority": "high",
        "cpu_limit": "0.8",
        "api_quota_per_hour": 1000
      }
    },
    "data": {
      "llm_config": {
        "temperature": 0.5,
        "max_tokens": 4096
      },
      "resource_allocation": {
        "priority": "medium",
        "memory_limit": "2GB"
      }
    }
  }
}