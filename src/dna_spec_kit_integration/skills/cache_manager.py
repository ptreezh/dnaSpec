"""
Cache Manager Skill - ç¼“å­˜åŒºç®¡ç†æŠ€èƒ½
ç”¨äºé¡¹ç›®åˆå§‹åŒ–æ—¶æ­å»ºç¼“å­˜åŒºï¼Œé¿å…AIäº§ç”Ÿå†—ä½™æ–‡ä»¶
"""
from typing import Dict, Any
import os
import json
from pathlib import Path
import time
from datetime import datetime, timedelta


# å…¨å±€ç¼“å­˜åŒºé…ç½®
_cache_config = {
    "cache_root": ".dnaspec/cache",
    "temp_area": ".dnaspec/temp",
    "staging_area": ".dnaspec/staging",
    "max_cache_size_mb": 500,
    "auto_cleanup_hours": 24,
    "gitignore_patterns": [
        ".dnaspec/temp/*",
        ".dnaspec/staging/*",
        "*_temp*",
        "*_debug*",
        "*_test_*.py",
        "ai_generated_*",
        "experiment_*"
    ]
}

_current_session = None


def execute(args: Dict[str, Any]) -> str:
    """
    æ‰§è¡Œç¼“å­˜åŒºç®¡ç†æŠ€èƒ½
    """
    operation = args.get("operation", "")
    project_path = args.get("project_path", ".")
    content = args.get("content", "")
    file_path = args.get("file_path", "")

    if operation == "init-cache":
        return initialize_cache_system(project_path)
    elif operation == "stage-file":
        return stage_file(file_path, content, project_path)
    elif operation == "validate-staged":
        return validate_staged_files(project_path)
    elif operation == "commit-staged":
        return commit_staged_files(project_path, args.get("message", ""))
    elif operation == "cleanup-cache":
        return cleanup_cache(project_path)
    elif operation == "cache-status":
        return get_cache_status(project_path)
    elif operation == "add-gitignore":
        return setup_gitignore(project_path)
    elif operation == "configure-rules":
        return configure_ai_rules(project_path, args.get("rules", {}))
    else:
        return f"æœªçŸ¥æ“ä½œ: {operation}"


def initialize_cache_system(project_path: str) -> str:
    """
    åœ¨é¡¹ç›®ä¸­åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
    """
    global _current_session
    project_root = Path(project_path).resolve()

    # åˆ›å»ºç¼“å­˜åŒºç›®å½•ç»“æ„
    cache_root = project_root / _cache_config["cache_root"]
    temp_area = cache_root / "temp"
    staging_area = cache_root / "staging"
    meta_dir = cache_root / "meta"

    for directory in [cache_root, temp_area, staging_area, meta_dir]:
        directory.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºç¼“å­˜é…ç½®æ–‡ä»¶
    config_file = meta_dir / "cache_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(_cache_config, f, indent=2, ensure_ascii=False)

    # åˆ›å»ºä¼šè¯æ–‡ä»¶
    _current_session = {
        "session_id": f"cache_session_{int(time.time())}",
        "start_time": datetime.now().isoformat(),
        "project_path": str(project_root),
        "files_staged": 0,
        "files_committed": 0,
        "temp_files": []
    }

    session_file = meta_dir / "current_session.json"
    with open(session_file, 'w', encoding='utf-8') as f:
        json.dump(_current_session, f, indent=2, ensure_ascii=False)

    # åˆ›å»º.gitignoreï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    setup_gitignore(project_path)

    result = f"""ğŸš€ DNASPECç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼

ğŸ“ ç¼“å­˜åŒºç»“æ„:
  - ä¸´æ—¶å·¥ä½œåŒº: {temp_area}
  - éªŒè¯æš‚å­˜åŒº: {staging_area}
  - å…ƒæ•°æ®ç›®å½•: {meta_dir}

ğŸ“‹ ä¼šè¯ID: {_current_session['session_id']}
ğŸ“… å¼€å§‹æ—¶é—´: {_current_session['start_time']}
ğŸ¯ é¡¹ç›®è·¯å¾„: {project_root}

âœ… ç¼“å­˜ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹ç®¡ç†AIç”Ÿæˆçš„æ–‡ä»¶...
"""

    return result


def stage_file(file_path: str, content: str, project_path: str) -> str:
    """
    å°†æ–‡ä»¶æš‚å­˜åˆ°éªŒè¯åŒº
    """
    global _current_session
    project_root = Path(project_path).resolve()
    staging_area = project_root / _cache_config["staging_area"]

    # æ›´æ–°ä¼šè¯
    _current_session = load_session(project_root)
    if not _current_session:
        return "é”™è¯¯: ç¼“å­˜ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œinit-cacheæ“ä½œ"

    # ç”Ÿæˆæš‚å­˜æ–‡ä»¶è·¯å¾„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    staging_filename = f"{timestamp}_{os.path.basename(file_path)}"
    staging_path = staging_area / staging_filename

    # å†™å…¥æš‚å­˜æ–‡ä»¶
    try:
        with open(staging_path, 'w', encoding='utf-8') as f:
            f.write(content)
    except Exception as e:
        return f"âŒ æš‚å­˜æ–‡ä»¶å¤±è´¥: {str(e)}"

    # åˆ›å»ºå…ƒæ•°æ®
    metadata = {
        "original_path": file_path,
        "staging_path": str(staging_path),
        "timestamp": timestamp,
        "size_bytes": len(content.encode('utf-8')),
        "session_id": _current_session["session_id"],
        "status": "staged",
        "validation_checks": []
    }

    metadata_file = staging_area / f"{staging_filename}.meta.json"
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    # æ›´æ–°ä¼šè¯ç»Ÿè®¡
    _current_session["files_staged"] += 1
    save_session(project_root, _current_session)

    result = f"""ğŸ“ æ–‡ä»¶å·²æš‚å­˜åˆ°éªŒè¯åŒº

ğŸ“„ åŸå§‹è·¯å¾„: {file_path}
ğŸ“ æš‚å­˜è·¯å¾„: {staging_path}
â° æš‚å­˜æ—¶é—´: {timestamp}
ğŸ“Š æ–‡ä»¶å¤§å°: {metadata['size_bytes']} å­—èŠ‚

ğŸ” æ–‡ä»¶æ­£åœ¨ç­‰å¾…éªŒè¯...
ä½¿ç”¨ 'validate-staged' å‘½ä»¤è¿›è¡ŒéªŒè¯
"""

    return result


def validate_staged_files(project_path: str) -> str:
    """
    éªŒè¯æš‚å­˜åŒºä¸­çš„æ–‡ä»¶
    """
    project_root = Path(project_path).resolve()
    staging_area = project_root / _cache_config["staging_area"]

    if not staging_area.exists():
        return "âŒ é”™è¯¯: æš‚å­˜åŒºä¸å­˜åœ¨"

    staged_files = list(staging_area.glob("*.meta.json"))
    if not staged_files:
        return "ğŸ“­ æš‚å­˜åŒºä¸­æ²¡æœ‰æ–‡ä»¶éœ€è¦éªŒè¯"

    validation_results = []

    for meta_file in staged_files:
        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            staging_path = Path(metadata["staging_path"])
            if not staging_path.exists():
                validation_results.append(f"âŒ {metadata['original_path']}: æš‚å­˜æ–‡ä»¶ä¸å­˜åœ¨")
                continue

            # åŸºæœ¬éªŒè¯æ£€æŸ¥
            checks = []

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if metadata["size_bytes"] == 0:
                checks.append("âš ï¸ æ–‡ä»¶ä¸ºç©º")
            else:
                checks.append("âœ… æ–‡ä»¶å¤§å°æ­£å¸¸")

            # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯
            with open(staging_path, 'r', encoding='utf-8') as f:
                content = f.read()

            sensitive_patterns = ["password", "api_key", "secret", "token", "private_key"]
            found_sensitive = []
            for pattern in sensitive_patterns:
                if pattern.lower() in content.lower():
                    found_sensitive.append(pattern)

            if found_sensitive:
                checks.append(f"âš ï¸ å‘ç°æ•æ„Ÿä¿¡æ¯: {', '.join(found_sensitive)}")
            else:
                checks.append("âœ… æœªå‘ç°æ•æ„Ÿä¿¡æ¯")

            # æ£€æŸ¥ä»£ç è¯­æ³•ï¼ˆå¦‚æœæ˜¯ä»£ç æ–‡ä»¶ï¼‰
            if metadata["original_path"].endswith(('.py', '.js', '.java', '.cpp', '.c')):
                if content.strip().startswith(('def ', 'function', 'class ', 'public class', 'import ', 'from ')):
                    checks.append("âœ… ä»£ç ç»“æ„æ­£å¸¸")
                else:
                    checks.append("âš ï¸ å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ä»£ç æ–‡ä»¶")

            metadata["validation_checks"] = checks
            metadata["status"] = "validated" if all("âœ…" in check for check in checks) else "needs_review"

            # ä¿å­˜æ›´æ–°çš„å…ƒæ•°æ®
            with open(meta_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            validation_results.append(f"{'âœ…' if metadata['status'] == 'validated' else 'âš ï¸'} {metadata['original_path']}: {'; '.join(checks)}")

        except Exception as e:
            validation_results.append(f"âŒ éªŒè¯ {meta_file.name} æ—¶å‡ºé”™: {str(e)}")

    result = "ğŸ” éªŒè¯ç»“æœ:\n" + "\n".join(validation_results)
    return result


def commit_staged_files(project_path: str, commit_message: str = "") -> str:
    """
    å°†éªŒè¯é€šè¿‡çš„æ–‡ä»¶æäº¤åˆ°ä¸»å·¥ä½œåŒº
    """
    project_root = Path(project_path).resolve()
    staging_area = project_root / _cache_config["staging_area"]
    _current_session = load_session(project_root)

    if not _current_session:
        return "âŒ é”™è¯¯: ç¼“å­˜ç³»ç»Ÿæœªåˆå§‹åŒ–"

    staged_files = list(staging_area.glob("*.meta.json"))
    if not staged_files:
        return "ğŸ“­ æš‚å­˜åŒºä¸­æ²¡æœ‰æ–‡ä»¶"

    committed_count = 0
    commit_results = []

    for meta_file in staged_files:
        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            if metadata["status"] != "validated":
                continue

            staging_path = Path(metadata["staging_path"])
            target_path = project_root / metadata["original_path"]

            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            target_path.parent.mkdir(parents=True, exist_ok=True)

            # ç§»åŠ¨æ–‡ä»¶åˆ°ä¸»å·¥ä½œåŒº
            import shutil
            shutil.move(str(staging_path), str(target_path))

            # æ›´æ–°Gitï¼ˆå¦‚æœæ˜¯Gitä»“åº“ï¼‰
            if (project_root / ".git").exists():
                try:
                    import subprocess
                    subprocess.run(["git", "add", str(target_path.relative(project_root))],
                              cwd=project_root, capture_output=True)
                except:
                    pass  # Gitæ“ä½œå¤±è´¥ä¸å½±å“æ–‡ä»¶ç§»åŠ¨

            # æ›´æ–°å…ƒæ•°æ®
            metadata["status"] = "committed"
            metadata["commit_time"] = datetime.now().isoformat()
            metadata["commit_message"] = commit_message

            with open(meta_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            committed_count += 1
            commit_results.append(f"âœ… {metadata['original_path']} å·²æäº¤åˆ°ä¸»å·¥ä½œåŒº")

        except Exception as e:
            commit_results.append(f"âŒ æäº¤ {meta_file.name} å¤±è´¥: {str(e)}")

    # æ›´æ–°ä¼šè¯ç»Ÿè®¡
    _current_session["files_committed"] += committed_count
    save_session(project_root, _current_session)

    result = f"ğŸ¯ æ–‡ä»¶æäº¤å®Œæˆ!

ğŸ“ˆ æäº¤ç»Ÿè®¡:
{chr(10).join(commit_results)}

âœ… æˆåŠŸæäº¤: {committed_count} ä¸ªæ–‡ä»¶
ğŸ“Š æ€»è®¡æäº¤: {_current_session['files_committed']} ä¸ªæ–‡ä»¶
ğŸ“ æäº¤ä¿¡æ¯: {commit_message or 'è‡ªåŠ¨æäº¤'}"

    return result


def setup_gitignore(project_path: str) -> str:
    """
    è®¾ç½®.gitignoreæ–‡ä»¶ï¼Œé¿å…ç¼“å­˜åŒºæ–‡ä»¶è¢«Gitè·Ÿè¸ª
    """
    project_root = Path(project_path).resolve()
    gitignore_path = project_root / ".gitignore"

    gitignore_content = """
# DNASPECç¼“å­˜åŒºæ–‡ä»¶ - é¿å…AIç”Ÿæˆæ–‡ä»¶è¢«Gitè·Ÿè¸ª
.dnaspec/temp/
.dnaspec/staging/
.dnaspec/cache/meta/

# AIç”Ÿæˆçš„ä¸´æ—¶æ–‡ä»¶
*ai_generated*
*experiment_*
*debug_*
*test_temp*
*_temp.*
.temp.*
cache_*.py
ai_works/

# IDEå’Œç¼–è¾‘å™¨ä¸´æ—¶æ–‡ä»¶
.vscode/
.idea/
*.swp
*.swo
*~

# Pythonç¼“å­˜
__pycache__/
*.py[cod]
*$py.class
*.egg-info/
"""

    try:
        if gitignore_path.exists():
            # è¯»å–ç°æœ‰å†…å®¹å¹¶åˆå¹¶
            existing_content = gitignore_path.read_text(encoding='utf-8')
            if ".dnaspec/" not in existing_content:
                gitignore_path.write_text(existing_content + gitignore_content, encoding='utf-8')
                return "âœ… .gitignore å·²æ›´æ–°ï¼Œæ·»åŠ DNASPECç¼“å­˜è§„åˆ™"
            else:
                return "â„¹ï¸ .gitignore å·²åŒ…å«DNASPECè§„åˆ™"
        else:
            gitignore_path.write_text(gitignore_content, encoding='utf-8')
            return "âœ… .gitignore å·²åˆ›å»ºï¼ŒåŒ…å«DNASPECç¼“å­˜è§„åˆ™"
    except Exception as e:
        return f"âŒ è®¾ç½®.gitignoreå¤±è´¥: {str(e)}"


def configure_ai_rules(project_path: str, rules: Dict[str, Any]) -> str:
    """
    é…ç½®AIæ–‡ä»¶ç®¡ç†è§„åˆ™
    """
    project_root = Path(project_path).resolve()
    meta_dir = project_root / _cache_config["cache_root"] / "meta"

    rules_file = meta_dir / "ai_rules.json"

    default_rules = {
        "auto_validation": True,
        "auto_commit": False,
        "max_file_size_kb": 1000,
        "allowed_extensions": [".py", ".js", ".ts", ".java", ".cpp", ".c", ".md", ".txt"],
        "blocked_patterns": ["password", "secret", "token", "api_key", "private_key"],
        "cleanup_after_hours": 24,
        "git_auto_add": True
    }

    # åˆå¹¶ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™
    default_rules.update(rules)

    try:
        with open(rules_file, 'w', encoding='utf-8') as f:
            json.dump(default_rules, f, indent=2, ensure_ascii=False)
        return f"âœ… AIè§„åˆ™é…ç½®å·²æ›´æ–°åˆ° {rules_file}"
    except Exception as e:
        return f"âŒ é…ç½®AIè§„åˆ™å¤±è´¥: {str(e)}"


def load_session(project_path: str) -> Dict[str, Any]:
    """åŠ è½½å½“å‰ä¼šè¯"""
    try:
        project_root = Path(project_path).resolve()
        session_file = project_root / _cache_config["cache_root"] / "meta" / "current_session.json"
        if session_file.exists():
            with open(session_file, 'r', encoding='utf-8') as f:
                return json.load(f)
    except:
        return None


def save_session(project_path: str, session: Dict[str, Any]) -> None:
    """ä¿å­˜ä¼šè¯"""
    try:
        project_root = Path(project_path).resolve()
        session_file = project_root / _cache_config["cache_root"] / "meta" / "current_session.json"
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session, f, indent=2, ensure_ascii=False)
    except:
        pass


def cleanup_cache(project_path: str) -> str:
    """æ¸…ç†è¿‡æœŸç¼“å­˜æ–‡ä»¶"""
    project_root = Path(project_path).resolve()
    staging_area = project_root / _cache_config["staging_area"]
    temp_area = project_root / _cache_config["temp"]

    cleanup_count = 0
    results = []

    # æ¸…ç†è¶…è¿‡24å°æ—¶çš„æš‚å­˜æ–‡ä»¶
    if staging_area.exists():
        cutoff_time = datetime.now() - timedelta(hours=_cache_config["auto_cleanup_hours"])
        for meta_file in staging_area.glob("*.meta.json"):
            try:
                with open(meta_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                staging_path = Path(metadata["staging_path"])
                if staging_path.exists():
                    file_time = datetime.fromisoformat(metadata["timestamp"])
                    if file_time < cutoff_time:
                        staging_path.unlink()
                        meta_file.unlink()
                        cleanup_count += 1
                        results.append(f"æ¸…ç†è¿‡æœŸæ–‡ä»¶: {metadata['original_path']}")
            except:
                continue

    if cleanup_count == 0:
        return "âœ… ç¼“å­˜åŒºæ¸…ç†å®Œæˆï¼Œæ²¡æœ‰è¿‡æœŸæ–‡ä»¶"
    else:
        return f"ğŸ§¹ ç¼“å­˜åŒºæ¸…ç†å®Œæˆï¼Œæ¸…ç†äº† {cleanup_count} ä¸ªè¿‡æœŸæ–‡ä»¶"


def get_cache_status(project_path: str) -> str:
    """è·å–ç¼“å­˜çŠ¶æ€"""
    project_root = Path(project_path).resolve()
    cache_root = project_root / _cache_config["cache_root"]

    if not cache_root.exists():
        return "âŒ ç¼“å­˜ç³»ç»Ÿæœªåˆå§‹åŒ–"

    staging_area = cache_root / "staging_area"
    temp_area = cache_root / "temp"

    staging_count = len(list(staging_area.glob("*.meta.json"))) if staging_area.exists() else 0
    temp_count = len(list(temp_area.rglob("*"))) if temp_area.exists() else 0

    session = load_session(project_path)
    session_info = ""
    if session:
        session_info = f"""
ä¼šè¯ä¿¡æ¯:
  - ä¼šè¯ID: {session.get('session_id', 'N/A')}
  - å¼€å§‹æ—¶é—´: {session.get('start_time', 'N/A')}
  - æš‚å­˜æ–‡ä»¶: {session.get('files_staged', 0)}
  - æäº¤æ–‡ä»¶: {session.get('files_committed', 0)}
"""

    return f"""ğŸ“Š DNASPECç¼“å­˜çŠ¶æ€

ğŸ“ ç¼“å­˜ç›®å½•: {cache_root}
ğŸ“‹ æš‚å­˜æ–‡ä»¶: {staging_count} ä¸ª
ğŸ—‚ï¸ ä¸´æ—¶æ–‡ä»¶: {temp_count} ä¸ª
ğŸ’¾ ç¼“å­˜å¤§å°é™åˆ¶: {_cache_config['max_cache_size_mb']}MB
ğŸ§¹ è‡ªåŠ¨æ¸…ç†: {_cache_config['auto_cleanup_hours']}å°æ—¶

{session_info}
"""