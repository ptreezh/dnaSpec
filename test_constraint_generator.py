"""
DNASPEC Constraint Generator End-to-End Test
å®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•
"""

import sys
from pathlib import Path

# Add skills to path
skills_dir = Path(__file__).parent / "skills" / "dnaspec-constraint-generator"
if str(skills_dir) not in sys.path:
    sys.path.insert(0, str(skills_dir))

from scripts.executor import ConstraintExecutor
from scripts.validator import ConstraintValidator
from scripts.calculator import ConstraintCalculator
from scripts.analyzer import ConstraintAnalyzer


def test_basic_execution():
    """æµ‹è¯•1: åŸºæœ¬æ‰§è¡ŒåŠŸèƒ½"""
    print("\n" + "="*70)
    print("æµ‹è¯• 1: åŸºæœ¬æ‰§è¡ŒåŠŸèƒ½")
    print("="*70)

    executor = ConstraintExecutor()
    result = executor.execute("ç”ŸæˆAPIæ€§èƒ½çº¦æŸï¼Œå“åº”æ—¶é—´å°äº100ms")

    assert result["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert "prompt_level" in result, "ç»“æœåº”åŒ…å«æç¤ºè¯å±‚æ¬¡"
    assert "prompt_content" in result, "ç»“æœåº”åŒ…å«æç¤ºè¯å†…å®¹"

    print(f"âœ… æç¤ºè¯å±‚æ¬¡: {result['prompt_level']}")
    print(f"âœ… æç¤ºè¯é•¿åº¦: {len(result['prompt_content'])} å­—ç¬¦")
    print("âœ… æµ‹è¯•é€šè¿‡: åŸºæœ¬æ‰§è¡ŒåŠŸèƒ½æ­£å¸¸")


def test_validation():
    """æµ‹è¯•2: éªŒè¯åŠŸèƒ½"""
    print("\n" + "="*70)
    print("æµ‹è¯• 2: éªŒè¯åŠŸèƒ½")
    print("="*70)

    validator = ConstraintValidator()

    # æµ‹è¯•æœ‰æ•ˆè¯·æ±‚
    valid_result = validator.validate("ç”ŸæˆAPIæ€§èƒ½çº¦æŸï¼Œå“åº”æ—¶é—´å°äº100ms")
    assert valid_result.is_valid == True, "æœ‰æ•ˆè¯·æ±‚åº”è¯¥é€šè¿‡éªŒè¯"
    print("âœ… æœ‰æ•ˆè¯·æ±‚éªŒè¯é€šè¿‡")

    # æµ‹è¯•ç©ºè¯·æ±‚
    empty_result = validator.validate("")
    assert empty_result.is_valid == False, "ç©ºè¯·æ±‚åº”è¯¥éªŒè¯å¤±è´¥"
    assert any(issue.severity.value == "critical" for issue in empty_result.issues), \
        "ç©ºè¯·æ±‚åº”è¯¥æœ‰criticalçº§åˆ«é—®é¢˜"
    print("âœ… ç©ºè¯·æ±‚éªŒè¯æ­£ç¡®æ‹’ç»")

    # æµ‹è¯•å¤ªçŸ­çš„è¯·æ±‚
    short_result = validator.validate("æµ‹è¯•")
    assert short_result.is_valid == False, "å¤ªçŸ­çš„è¯·æ±‚åº”è¯¥éªŒè¯å¤±è´¥"
    print("âœ… çŸ­è¯·æ±‚éªŒè¯æ­£ç¡®æ‹’ç»")

    print("âœ… æµ‹è¯•é€šè¿‡: éªŒè¯åŠŸèƒ½æ­£å¸¸")


def test_metrics_calculation():
    """æµ‹è¯•3: æŒ‡æ ‡è®¡ç®—"""
    print("\n" + "="*70)
    print("æµ‹è¯• 3: æŒ‡æ ‡è®¡ç®—")
    print("="*70)

    calculator = ConstraintCalculator()

    # æµ‹è¯•æ€§èƒ½çº¦æŸ
    perf_metrics = calculator.calculate("APIå“åº”æ—¶é—´å°äº100msï¼Œæ”¯æŒ1000 QPS")
    assert perf_metrics.has_performance_constraint == True, "åº”è¯¥æ£€æµ‹åˆ°æ€§èƒ½çº¦æŸ"
    assert perf_metrics.specificity_score > 0.5, "å…·ä½“æ€§åˆ†æ•°åº”è¯¥è¾ƒé«˜ï¼ˆæœ‰æ•°å­—å’Œå•ä½ï¼‰"
    print(f"âœ… æ€§èƒ½çº¦æŸ: å¤æ‚åº¦={perf_metrics.complexity_score:.2f}, å…·ä½“æ€§={perf_metrics.specificity_score:.2f}")

    # æµ‹è¯•å®‰å…¨çº¦æŸ
    sec_metrics = calculator.calculate("ç³»ç»Ÿéœ€è¦é«˜å®‰å…¨æ€§ï¼Œä½¿ç”¨åŠ å¯†å’Œè®¤è¯")
    assert sec_metrics.has_security_constraint == True, "åº”è¯¥æ£€æµ‹åˆ°å®‰å…¨çº¦æŸ"
    print(f"âœ… å®‰å…¨çº¦æŸ: å¤æ‚åº¦={sec_metrics.complexity_score:.2f}")

    # æµ‹è¯•å¤šçº¦æŸç±»å‹
    multi_metrics = calculator.calculate("ç³»ç»Ÿéœ€è¦é«˜æ€§èƒ½å’Œé«˜å®‰å…¨æ€§ï¼Œæ”¯æŒè®¤è¯å’ŒåŠ å¯†")
    type_count = sum([
        multi_metrics.has_performance_constraint,
        multi_metrics.has_security_constraint,
        multi_metrics.has_functional_constraint,
        multi_metrics.has_technical_constraint
    ])
    assert type_count >= 2, "åº”è¯¥æ£€æµ‹åˆ°å¤šç§çº¦æŸç±»å‹"
    print(f"âœ… å¤šçº¦æŸç±»å‹: {type_count} ç§")

    print("âœ… æµ‹è¯•é€šè¿‡: æŒ‡æ ‡è®¡ç®—æ­£å¸¸")


def test_analysis():
    """æµ‹è¯•4: åˆ†æåŠŸèƒ½"""
    print("\n" + "="*70)
    print("æµ‹è¯• 4: åˆ†æåŠŸèƒ½")
    print("="*70)

    analyzer = ConstraintAnalyzer()

    # æµ‹è¯•çº¦æŸç±»å‹æ£€æµ‹
    analysis = analyzer.analyze("ç³»ç»Ÿéœ€è¦é«˜æ€§èƒ½å’Œé«˜å®‰å…¨æ€§")
    detected_types = [t.value for t in analysis.detected_types]
    assert "performance" in detected_types, "åº”è¯¥æ£€æµ‹åˆ°æ€§èƒ½ç±»å‹"
    assert "security" in detected_types, "åº”è¯¥æ£€æµ‹åˆ°å®‰å…¨ç±»å‹"
    print(f"âœ… æ£€æµ‹åˆ°çš„ç±»å‹: {detected_types}")

    # æµ‹è¯•è´¨é‡åˆ†æ•°
    assert "clarity" in analysis.quality_scores, "åº”è¯¥æœ‰æ¸…æ™°åº¦åˆ†æ•°"
    assert "completeness" in analysis.quality_scores, "åº”è¯¥æœ‰å®Œæ•´æ€§åˆ†æ•°"
    assert "verifiability" in analysis.quality_scores, "åº”è¯¥æœ‰å¯éªŒè¯æ€§åˆ†æ•°"
    print(f"âœ… è´¨é‡åˆ†æ•°: {analysis.quality_scores}")

    # æµ‹è¯•å†²çªæ£€æµ‹
    conflict_analysis = analyzer.analyze("ç³»ç»Ÿè¦å¿«ä½†ä¹Ÿè¦éå¸¸å®‰å…¨")
    assert len(conflict_analysis.potential_conflicts) > 0, "åº”è¯¥æ£€æµ‹åˆ°æ€§èƒ½ä¸å®‰å…¨çš„æ½œåœ¨å†²çª"
    print(f"âœ… æ£€æµ‹åˆ°å†²çª: {conflict_analysis.potential_conflicts}")

    # æµ‹è¯•å»ºè®®ç”Ÿæˆ
    assert len(analysis.recommendations) > 0, "åº”è¯¥ç”Ÿæˆå»ºè®®"
    print(f"âœ… ç”Ÿæˆå»ºè®®: {len(analysis.recommendations)} æ¡")

    print("âœ… æµ‹è¯•é€šè¿‡: åˆ†æåŠŸèƒ½æ­£å¸¸")


def test_level_selection():
    """æµ‹è¯•5: æç¤ºè¯å±‚æ¬¡é€‰æ‹©"""
    print("\n" + "="*70)
    print("æµ‹è¯• 5: æç¤ºè¯å±‚æ¬¡é€‰æ‹©")
    print("="*70)

    executor = ConstraintExecutor()

    # ç®€å•è¯·æ±‚ â†’ 00æˆ–01
    simple_result = executor.execute("ç”ŸæˆAPIæ€§èƒ½çº¦æŸæ¡ä»¶")
    assert simple_result["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert simple_result["prompt_level"] in ["00", "01"], "ç®€å•è¯·æ±‚åº”è¯¥ä½¿ç”¨åŸºç¡€å±‚æ¬¡"
    print(f"âœ… ç®€å•è¯·æ±‚ â†’ å±‚æ¬¡ {simple_result['prompt_level']}")

    # ä¸­ç­‰å¤æ‚åº¦ â†’ 01æˆ–02
    medium_result = executor.execute("ç”ŸæˆAPIæ€§èƒ½å’Œå®‰å…¨çº¦æŸï¼Œéœ€è¦è®¤è¯å’ŒåŠ å¯†")
    assert medium_result["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert medium_result["prompt_level"] in ["01", "02"], "ä¸­ç­‰è¯·æ±‚åº”è¯¥ä½¿ç”¨ä¸­çº§å±‚æ¬¡"
    print(f"âœ… ä¸­ç­‰è¯·æ±‚ â†’ å±‚æ¬¡ {medium_result['prompt_level']}")

    # æœ‰å†²çª â†’ 03
    conflict_result = executor.execute("ç³»ç»Ÿè¦å¿«ä½†ä¹Ÿè¦å®Œå…¨å®‰å…¨ï¼Œä½æˆæœ¬ä½†é«˜è´¨é‡")
    assert conflict_result["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert conflict_result["prompt_level"] == "03", "æœ‰å†²çªçš„è¯·æ±‚åº”è¯¥ä½¿ç”¨é«˜çº§å±‚æ¬¡"
    print(f"âœ… å†²çªè¯·æ±‚ â†’ å±‚æ¬¡ {conflict_result['prompt_level']}")

    # å¼ºåˆ¶å±‚æ¬¡
    force_result = executor.execute("è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„è¯·æ±‚å†…å®¹", force_level="01")
    assert force_result["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert force_result["prompt_level"] == "01", "åº”è¯¥å°Šé‡å¼ºåˆ¶å±‚æ¬¡å‚æ•°"
    print(f"âœ… å¼ºåˆ¶å±‚æ¬¡ â†’ å±‚æ¬¡ {force_result['prompt_level']}")

    print("âœ… æµ‹è¯•é€šè¿‡: å±‚æ¬¡é€‰æ‹©é€»è¾‘æ­£å¸¸")


def test_end_to_end_scenarios():
    """æµ‹è¯•6: ç«¯åˆ°ç«¯åœºæ™¯"""
    print("\n" + "="*70)
    print("æµ‹è¯• 6: ç«¯åˆ°ç«¯åœºæ™¯")
    print("="*70)

    executor = ConstraintExecutor()

    scenarios = [
        {
            "name": "ç®€å•æ€§èƒ½çº¦æŸ",
            "request": "APIå“åº”æ—¶é—´è¦å°äº100ms",
            "expected_level": ["00", "01"]
        },
        {
            "name": "å¤æ‚å¤šçº¦æŸ",
            "request": "ç³»ç»Ÿéœ€è¦é«˜æ€§èƒ½ï¼ˆP95<200msï¼‰ã€é«˜å®‰å…¨æ€§ï¼ˆåŠ å¯†+è®¤è¯ï¼‰ã€é«˜å¯ç”¨æ€§ï¼ˆ99.99%ï¼‰ï¼Œæ”¯æŒ10000 QPS",
            "expected_level": ["02", "03"]
        },
        {
            "name": "æœ‰å†²çªçš„çº¦æŸ",
            "request": "ä½æˆæœ¬ä½†é«˜è´¨é‡ï¼Œå¿«é€Ÿä¸Šçº¿ä½†åŠŸèƒ½å®Œæ•´",
            "expected_level": ["03"]
        }
    ]

    for scenario in scenarios:
        print(f"\nåœºæ™¯: {scenario['name']}")
        print(f"è¯·æ±‚: {scenario['request']}")

        result = executor.execute(scenario['request'])

        assert result["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
        assert result["prompt_level"] in scenario["expected_level"], \
            f"å±‚æ¬¡ {result['prompt_level']} åº”è¯¥åœ¨ {scenario['expected_level']} ä¸­"

        print(f"  âœ… å±‚æ¬¡: {result['prompt_level']}")
        print(f"  âœ… å¤æ‚åº¦: {result['metrics'].complexity_score:.2f}")
        print(f"  âœ… çº¦æŸç±»å‹: {len(result['analysis'].detected_types)} ç§")
        print(f"  âœ… å»ºè®®: {len(result['recommendations'])} æ¡")

    print("\nâœ… æµ‹è¯•é€šè¿‡: ç«¯åˆ°ç«¯åœºæ™¯æ­£å¸¸")


def test_recommendations():
    """æµ‹è¯•7: å»ºè®®ç”Ÿæˆ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 7: å»ºè®®ç”Ÿæˆ")
    print("="*70)

    executor = ConstraintExecutor()

    # ä½å…·ä½“æ€§ â†’ åº”è¯¥æœ‰SMARTå»ºè®®
    low_specificity = executor.execute("ç³»ç»Ÿæ€§èƒ½è¦å¥½ï¼Œå“åº”é€Ÿåº¦å¿«")
    assert low_specificity["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert any("SMART" in rec or "å…·ä½“" in rec for rec in low_specificity["recommendations"]), \
        "ä½å…·ä½“æ€§åº”è¯¥å»ºè®®ä½¿ç”¨SMARTåŸåˆ™"
    print("âœ… ä½å…·ä½“æ€§ç”ŸæˆSMARTå»ºè®®")

    # æœ‰å†²çª â†’ åº”è¯¥æœ‰å†²çªå¤„ç†å»ºè®®
    has_conflicts = executor.execute("ç³»ç»Ÿè¦å¿«é€Ÿä½†ä¹Ÿè¦éå¸¸å®‰å…¨ï¼Œéœ€è¦æƒè¡¡")
    assert has_conflicts["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert any("å†²çª" in rec or "ä¼˜å…ˆçº§" in rec for rec in has_conflicts["recommendations"]), \
        "æœ‰å†²çªåº”è¯¥å»ºè®®ä¼˜å…ˆçº§æ’åº"
    print("âœ… å†²çªç”Ÿæˆå¤„ç†å»ºè®®")

    # é«˜å¤æ‚åº¦ â†’ åº”è¯¥æœ‰åˆ†é˜¶æ®µå»ºè®®
    high_complexity = executor.execute(
        "è¿™æ˜¯ä¸€ä¸ªæå…¶å¤æ‚çš„ä¼ä¸šçº§åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œ"
        "åŒ…å«é«˜æ€§èƒ½è¦æ±‚ï¼ˆæ”¯æŒ10ä¸‡å¹¶å‘ï¼‰ã€"
        "é«˜å®‰å…¨æ€§è¦æ±‚ï¼ˆæ»¡è¶³SOC2å’ŒGDPRåˆè§„ï¼‰ã€"
        "é«˜å¯ç”¨æ€§è¦æ±‚ï¼ˆ99.999%ï¼‰ã€"
        "å¤æ‚çš„åŠŸèƒ½è¦æ±‚ï¼ˆæ”¯æŒå¤šç§ä¸šåŠ¡åœºæ™¯å’Œå·¥ä½œæµï¼‰ã€"
        "å¤æ‚çš„æŠ€æœ¯æ ˆï¼ˆå¾®æœåŠ¡æ¶æ„ã€å¤šè¯­è¨€ã€å¤šæ•°æ®åº“ï¼‰ã€"
        "ä»¥åŠä¸¥æ ¼çš„ä¸šåŠ¡è§„åˆ™å’ŒæŠ€æœ¯é™åˆ¶ï¼Œ"
        "éœ€è¦æ»¡è¶³å¤šä¸ªåˆè§„æ€§è¦æ±‚ï¼Œ"
        "åŒæ—¶è¦è€ƒè™‘æˆæœ¬çº¦æŸå’Œäº¤ä»˜æ—¶é—´é™åˆ¶",
        context={"project_size": "enterprise", "team_size": 100}
    )
    assert high_complexity["success"] == True, "æ‰§è¡Œåº”è¯¥æˆåŠŸ"
    assert any("é˜¶æ®µ" in rec or "åˆ†æ­¥" in rec for rec in high_complexity["recommendations"]), \
        "é«˜å¤æ‚åº¦åº”è¯¥å»ºè®®åˆ†é˜¶æ®µå¤„ç†"
    print("âœ… é«˜å¤æ‚åº¦ç”Ÿæˆåˆ†é˜¶æ®µå»ºè®®")

    print("âœ… æµ‹è¯•é€šè¿‡: å»ºè®®ç”Ÿæˆæ­£å¸¸")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("DNASPEC CONSTRAINT GENERATOR æµ‹è¯•å¥—ä»¶")
    print("="*70)

    tests = [
        test_basic_execution,
        test_validation,
        test_metrics_calculation,
        test_analysis,
        test_level_selection,
        test_end_to_end_scenarios,
        test_recommendations
    ]

    passed = 0
    failed = 0

    for test in tests:
        try:
            test()
            passed += 1
        except AssertionError as e:
            failed += 1
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {test.__name__}")
            print(f"   é”™è¯¯: {e}")
        except Exception as e:
            failed += 1
            print(f"\nâŒ æµ‹è¯•é”™è¯¯: {test.__name__}")
            print(f"   å¼‚å¸¸: {e}")

    # æ€»ç»“
    print("\n" + "="*70)
    print("æµ‹è¯•æ€»ç»“")
    print("="*70)
    print(f"æ€»è®¡: {len(tests)} ä¸ªæµ‹è¯•")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DNASPEC CONSTRAINT GENERATOR æŠ€èƒ½å°±ç»ªã€‚")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)
