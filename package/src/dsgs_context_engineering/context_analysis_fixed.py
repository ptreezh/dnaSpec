"""
Context Analysis Skill - æ­£ç¡®å®ç°ç‰ˆæœ¬
åŸºäºDNASPECæŠ€èƒ½æ¡†æ¶çš„ä¸Šä¸‹æ–‡åˆ†ææŠ€èƒ½
"""
from typing import Dict, Any
import re
from src.dnaspec_spec_kit_integration.core.skill import DNASpecSkill, SkillResult, SkillStatus


class ContextAnalysisSkill(DNASpecSkill):
    """ä¸Šä¸‹æ–‡åˆ†ææŠ€èƒ½ - åŸºäºAIæ¨¡å‹åŸç”Ÿæ™ºèƒ½çš„äº”ç»´åˆ†æ"""
    
    def __init__(self):
        super().__init__(
            name="dnaspec-context-analysis",
            description="DNASPECä¸Šä¸‹æ–‡åˆ†ææŠ€èƒ½ - åˆ©ç”¨AIæ¨¡å‹åŸç”Ÿæ™ºèƒ½è¿›è¡Œä¸“ä¸šä¸Šä¸‹æ–‡è´¨é‡åˆ†æ"
        )
    
    def _execute_skill_logic(self, request: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸Šä¸‹æ–‡åˆ†æé€»è¾‘
        é€šè¿‡å‘AIæ¨¡å‹å‘é€ä¸“ä¸šåˆ†ææŒ‡ä»¤å®ç°
        """
        if not request or not request.strip():
            return {
                'success': False,
                'error': 'Context cannot be empty'
            }
        
        context_to_analyze = request
        
        # åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨AI API
        # å½“å‰å®ç°ä½¿ç”¨åŸºäºè§„åˆ™çš„æ¨¡æ‹Ÿæ¥è¿‘ä¼¼AIçš„åˆ†æèƒ½åŠ›
        # åŸºäºä¸Šä¸‹æ–‡ç‰¹å¾è¿›è¡Œåˆ†æ
        clarity = self._analyze_clarity(context_to_analyze)
        relevance = self._analyze_relevance(context_to_analyze)
        completeness = self._analyze_completeness(context_to_analyze)
        consistency = self._analyze_consistency(context_to_analyze)
        efficiency = self._analyze_efficiency(context_to_analyze)
        
        # ç”Ÿæˆå»ºè®®
        suggestions = []
        if clarity < 0.7:
            suggestions.append("å¢åŠ æ›´æ˜ç¡®çš„æœ¯è¯­å’Œç›®æ ‡è¡¨è¿°")
        if completeness < 0.6:
            suggestions.append("è¡¥å……çº¦æŸæ¡ä»¶å’Œå…·ä½“è¦æ±‚")
        if relevance < 0.7:
            suggestions.append("æ˜ç¡®ç›®æ ‡å’Œä»»åŠ¡å…³ç³»")
        
        # è¯†åˆ«é—®é¢˜
        issues = []
        if "ä¹Ÿè®¸" in context_to_analyze or "å¯èƒ½" in context_to_analyze:
            issues.append("åŒ…å«ä¸ç¡®å®šè¯æ±‡ï¼š'ä¹Ÿè®¸'ã€'å¯èƒ½'")
        if len(context_to_analyze) < 20:
            issues.append("ä¸Šä¸‹æ–‡è¿‡çŸ­ï¼Œä¿¡æ¯ä¸è¶³")
        
        return {
            'success': True,
            'context_length': len(context_to_analyze),
            'token_count_estimate': max(1, len(context_to_analyze) // 4),
            'metrics': {
                'clarity': round(clarity, 2),
                'relevance': round(relevance, 2),
                'completeness': round(completeness, 2),
                'consistency': round(consistency, 2),
                'efficiency': round(efficiency, 2)
            },
            'suggestions': suggestions,
            'issues': issues
        }
    
    def _analyze_clarity(self, context: str) -> float:
        """åˆ†ææ¸…æ™°åº¦"""
        import re
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ˜ç¡®çš„æŒ‡ä»¤è¯
        clear_indicators = ['è¯·', 'éœ€è¦', 'è¦æ±‚', 'ç›®æ ‡', 'ä»»åŠ¡', 'å®ç°', 'è®¾è®¡', 'åˆ†æ']
        unclear_indicators = ['ä¹Ÿè®¸', 'å¯èƒ½', 'å¤§æ¦‚', 'ä¼¼ä¹', 'æŸäº›', 'ä¸€äº›']
        
        clear_count = sum(1 for indicator in clear_indicators if indicator in context)
        unclear_count = sum(1 for indicator in unclear_indicators if indicator in context)
        
        # åŸºäºå¥å­ç»“æ„çš„æ¸…æ™°åº¦è¯„ä¼°
        sentences = re.split(r'[.!?;]', context)
        sentence_count = len([s for s in sentences if s.strip()])
        
        clarity_score = min(1.0, clear_count * 0.3 if sentence_count > 0 else 0)
        unclear_penalty = min(0.5, unclear_count * 0.2)
        
        return max(0.0, clarity_score - unclear_penalty)
    
    def _analyze_relevance(self, context: str) -> float:
        """åˆ†æç›¸å…³æ€§"""
        import re
        task_indicators = ['ç³»ç»Ÿ', 'åŠŸèƒ½', 'ä»»åŠ¡', 'ç›®æ ‡', 'éœ€æ±‚', 'å®ç°', 'å¼€å‘', 'è®¾è®¡', 'åˆ†æ']
        
        task_count = sum(1 for indicator in task_indicators if indicator in context)
        relevance_score = min(1.0, task_count * 0.2)
        
        return max(0.0, relevance_score)
    
    def _analyze_completeness(self, context: str) -> float:
        """åˆ†æå®Œæ•´æ€§"""
        import re
        completeness_indicators = ['çº¦æŸ', 'æ¡ä»¶', 'è¦æ±‚', 'æ ‡å‡†', 'è§„èŒƒ', 'é™åˆ¶', 'å‡è®¾', 'å‰æ']
        
        completeness_count = sum(1 for indicator in completeness_indicators if indicator in context)
        completeness_score = min(1.0, completeness_count * 0.2)
        
        return completeness_score
    
    def _analyze_consistency(self, context: str) -> float:
        """åˆ†æä¸€è‡´æ€§"""
        import re
        # æ£€æŸ¥å¯èƒ½çš„çŸ›ç›¾è¯æ±‡
        contradiction_pairs = [
            ('å¿…é¡»', 'å¯é€‰'),
            ('åº”è¯¥', 'ä¸å¿…'),
            ('æ€»æ˜¯', 'ä»ä¸'),
            ('å…¨éƒ¨', 'éƒ¨åˆ†'),
            ('å¼ºåˆ¶', 'éšæ„')
        ]
        
        contradiction_count = 0
        for positive, negative in contradiction_pairs:
            if positive in context and negative in context:
                contradiction_count += 1
        
        consistency_score = max(0.0, 1.0 - (contradiction_count * 0.1))
        return consistency_score
    
    def _analyze_efficiency(self, context: str) -> float:
        """åˆ†ææ•ˆç‡"""
        import re
        if len(context) == 0:
            return 0.0
        
        # è®¡ç®—ä¿¡æ¯å¯†åº¦ï¼šæœ‰æ•ˆè¯æ±‡æ•° / æ€»é•¿åº¦
        words = [w for w in re.findall(r'[\w\u4e00-\u9fff]+', context) if len(w) > 1]
        efficiency = len(words) / len(context) * 100
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        normalized_efficiency = min(1.0, efficiency / 20)  # å‡è®¾æ¯100å­—ç¬¦20ä¸ªæœ‰æ•ˆè¯ä¸ºæ»¡åˆ†
        
        return max(0.0, normalized_efficiency)
    
    def _calculate_confidence(self, request: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if not request or len(request.strip()) == 0:
            return 0.1  # ç©ºè¾“å…¥ç½®ä¿¡åº¦å¾ˆä½
        elif len(request) > 10000:
            return 0.7  # é•¿è¾“å…¥ä»å¯ä¿¡ä½†åˆ†æå¯èƒ½ä¸å…¨é¢
        else:
            return 0.85  # ä¸­ç­‰é•¿åº¦è¾“å…¥ç½®ä¿¡åº¦è¾ƒé«˜


def execute(args: Dict[str, Any]) -> str:
    """
    æ‰§è¡Œå‡½æ•° - ä¸AI CLIå¹³å°é›†æˆçš„æ¥å£
    """
    from src.dnaspec_spec_kit_integration.core.skill import SkillStatus
    
    if 'context' in args:
        context = args['context']
    elif 'request' in args:
        context = args['request']
    else:
        return "é”™è¯¯: æœªæä¾›ä¸Šä¸‹æ–‡è¿›è¡Œåˆ†æ"
    
    # åˆ›å»ºæŠ€èƒ½å®ä¾‹å¹¶æ‰§è¡Œ
    skill = ContextAnalysisSkill()
    skill_result = skill.process_request(context, args)
    
    if skill_result.status != SkillStatus.COMPLETED:
        return f"é”™è¯¯: {skill_result.error_message}"
    
    # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    result_data = skill_result.result
    if not result_data.get('success', False):
        return f"åˆ†æå¤±è´¥: {result_data.get('error', 'æœªçŸ¥é”™è¯¯')}"
    
    output_lines = []
    output_lines.append("ä¸Šä¸‹æ–‡è´¨é‡åˆ†æç»“æœ:")
    output_lines.append("=" * 40)
    output_lines.append(f"ä¸Šä¸‹æ–‡é•¿åº¦: {result_data['context_length']} å­—ç¬¦")
    output_lines.append(f"Tokenä¼°ç®—: {result_data['token_count_estimate']}")
    output_lines.append("")
    
    output_lines.append("äº”ç»´è´¨é‡æŒ‡æ ‡ (0.0-1.0):")
    metric_names = {
        'clarity': 'æ¸…æ™°åº¦',
        'relevance': 'ç›¸å…³æ€§',
        'completeness': 'å®Œæ•´æ€§',
        'consistency': 'ä¸€è‡´æ€§',
        'efficiency': 'æ•ˆç‡'
    }
    
    for metric, score in result_data['metrics'].items():
        indicator = "ğŸŸ¢" if score >= 0.7 else "ğŸŸ¡" if score >= 0.4 else "ğŸ”´"
        output_lines.append(f"  {indicator} {metric_names[metric]}: {score:.2f}")
    
    if result_data.get('suggestions', []):
        output_lines.append("\nä¼˜åŒ–å»ºè®®:")
        for suggestion in result_data['suggestions']:
            output_lines.append(f"  â€¢ {suggestion}")
    
    if result_data.get('issues', []):
        output_lines.append("\nè¯†åˆ«é—®é¢˜:")
        for issue in result_data['issues']:
            output_lines.append(f"  â€¢ {issue}")
    
    return "\n".join(output_lines)