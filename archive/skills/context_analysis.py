"""
context_analysis.py
ä¸Šä¸‹æ–‡åˆ†ææŠ€èƒ½ - ç¬¦åˆClaude Skillsè§„èŒƒ
"""
from typing import Dict, Any, List
import re
from datetime import datetime

def execute(args: Dict[str, Any]) -> str:
    """
    Claude Skillsæ ‡å‡†æ‰§è¡Œå…¥å£
    """
    context = args.get("context", "") or args.get("request", "") or args.get("description", "")
    detailed = args.get("detailed", False)
    
    if not context.strip():
        return "âŒ é”™è¯¯: æœªæä¾›è¦åˆ†æçš„ä¸Šä¸‹æ–‡"
    
    # æ‰§è¡Œä¸Šä¸‹æ–‡åˆ†æ
    analysis_result = perform_context_analysis(context)
    
    # æ ¼å¼åŒ–è¾“å‡º
    return format_analysis_output(analysis_result, detailed)


def perform_context_analysis(context: str) -> Dict[str, Any]:
    """
    æ‰§è¡Œä¸Šä¸‹æ–‡åˆ†æ - å®šé‡åˆ†æéƒ¨åˆ†
    """
    # åˆ†æä¸Šä¸‹æ–‡ç‰¹å¾
    has_goals = bool(re.search(r'(ç›®æ ‡|ç›®çš„|goal|objective|requirement|éœ€æ±‚)', context, re.IGNORECASE))
    has_requirements = bool(re.search(r'(è¦æ±‚|éœ€æ±‚|requirement|specification|éœ€è¦|éœ€è¦)', context, re.IGNORECASE))
    has_constraints = bool(re.search(r'(çº¦æŸ|é™åˆ¶|constraint|limitation|é™åˆ¶|æ¡ä»¶)', context, re.IGNORECASE))
    has_structure = bool(re.search(r'(^#+\s|^##+\s|^-\s|^\d+\.)', context, re.MULTILINE))
    
    # è®¡ç®—äº”ç»´è´¨é‡æŒ‡æ ‡
    clarity_score = 0.5
    if has_goals:
        clarity_score += 0.2
    if has_requirements:
        clarity_score += 0.15
    clarity_score = min(1.0, clarity_score)
    
    relevance_score = 0.7  # åŸºç¡€ç›¸å…³æ€§
    if has_goals or has_requirements:
        relevance_score += 0.1
    relevance_score = min(1.0, relevance_score)
    
    completeness_score = 0.3
    if has_requirements:
        completeness_score += 0.3
    if has_constraints:
        completeness_score += 0.2
    completeness_score = min(1.0, completeness_score)
    
    # ä¸€è‡´æ€§ï¼šæ£€æŸ¥çŸ›ç›¾è¯æ±‡
    contradiction_pairs = [
        ('å¿…é¡»', 'å¯é€‰'), ('åº”è¯¥', 'ä¸å¿…'), ('æ€»æ˜¯', 'ä»ä¸'), ('å…¨éƒ¨', 'éƒ¨åˆ†'), ('å¼ºåˆ¶', 'éšæ„')
    ]
    contradiction_count = sum(1 for pos, neg in contradiction_pairs if pos in context and neg in context)
    consistency_score = max(0.0, 0.9 - (contradiction_count * 0.15))
    
    # æ•ˆç‡ï¼šä¿¡æ¯å¯†åº¦
    word_count = len([w for w in context.split() if len(w) > 1])
    efficiency_score = min(1.0, word_count / max(1, len(context) / 4))
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    suggestions = []
    if not has_goals:
        suggestions.append("æ˜ç¡®ç›®æ ‡å’Œé¢„æœŸç»“æœ")
    if not has_requirements:
        suggestions.append("è¡¥å……å…·ä½“çš„çº¦æŸæ¡ä»¶å’Œè¦æ±‚")
    if contradiction_count > 0:
        suggestions.append(f"è§£å†³æ£€æµ‹åˆ°çš„{contradiction_count}ä¸ªé€»è¾‘çŸ›ç›¾")
    
    # è¯†åˆ«é—®é¢˜
    issues = []
    if contradiction_count > 0:
        issues.append(f"æ£€æµ‹åˆ°é€»è¾‘çŸ›ç›¾: {contradiction_count}å¤„")
    if len(context) < 20:
        issues.append("ä¸Šä¸‹æ–‡è¿‡çŸ­ï¼Œä¿¡æ¯ä¸è¶³")
    if not has_structure and len(context) > 50:
        issues.append("ç¼ºä¹æ¸…æ™°çš„ç»“æ„ç»„ç»‡")
    
    return {
        'context_length': len(context),
        'token_count_estimate': max(1, len(context) // 4),
        'metrics': {
            'clarity': round(clarity_score, 2),
            'relevance': round(relevance_score, 2),
            'completeness': round(completeness_score, 2),
            'consistency': round(consistency_score, 2),
            'efficiency': round(efficiency_score, 2)
        },
        'suggestions': suggestions,
        'issues': issues
    }


def format_analysis_output(analysis: Dict[str, Any], detailed: bool = False) -> str:
    """æ ¼å¼åŒ–åˆ†æè¾“å‡º"""
    output_lines = []
    output_lines.append("ğŸ“‹ ä¸Šä¸‹æ–‡è´¨é‡åˆ†æç»“æœ")
    output_lines.append(f"é•¿åº¦: {analysis['context_length']} å­—ç¬¦")
    output_lines.append(f"Tokenä¼°ç®—: {analysis['token_count_estimate']}")
    output_lines.append("")

    output_lines.append("äº”ç»´è´¨é‡æŒ‡æ ‡ (0.0-1.0):")
    metric_names = {
        'clarity': 'æ¸…æ™°åº¦',
        'relevance': 'ç›¸å…³æ€§', 
        'completeness': 'å®Œæ•´æ€§',
        'consistency': 'ä¸€è‡´æ€§',
        'efficiency': 'æ•ˆç‡'
    }

    for metric, score in analysis['metrics'].items():
        indicator = "ğŸŸ¢" if score >= 0.7 else "ğŸŸ¡" if score >= 0.4 else "ğŸ”´"
        output_lines.append(f"  {indicator} {metric_names.get(metric, metric)}: {score:.2f}")

    if analysis['suggestions']:
        output_lines.append("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for suggestion in analysis['suggestions'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            output_lines.append(f"  â€¢ {suggestion}")

    if analysis['issues']:
        output_lines.append("\nâš ï¸  è¯†åˆ«é—®é¢˜:")
        for issue in analysis['issues']:
            output_lines.append(f"  â€¢ {issue}")

    if not detailed:
        output_lines.append("\nğŸ’¡ ä½¿ç”¨ detailed=true å‚æ•°è·å–è¯¦ç»†åˆ†æ")
    
    return "\n".join(output_lines)


def get_manifest() -> Dict[str, Any]:
    """
    Claude Skillsæ ‡å‡†æŠ€èƒ½æ¸…å•
    """
    return {
        "name": "dnaspec-context-analysis",
        "description": "åˆ†æä¸Šä¸‹æ–‡è´¨é‡çš„æŠ€èƒ½ï¼Œæä¾›äº”ç»´è´¨é‡è¯„ä¼°",
        "version": "1.0.0",
        "created_at": datetime.now().isoformat(),
        "parameters": {
            "type": "object",
            "properties": {
                "context": {
                    "type": "string",
                    "description": "è¦åˆ†æçš„ä¸Šä¸‹æ–‡"
                },
                "request": {
                    "type": "string",
                    "description": "è¦åˆ†æçš„è¯·æ±‚ï¼ˆcontextçš„åˆ«åï¼‰"
                },
                "description": {
                    "type": "string",
                    "description": "è¦åˆ†æçš„æè¿°ï¼ˆcontextçš„åˆ«åï¼‰"
                },
                "detailed": {
                    "type": "boolean",
                    "description": "æ˜¯å¦è¿”å›è¯¦ç»†åˆ†æ",
                    "default": False
                }
            },
            "required": ["context"]
        }
    }