"""
Claude Skills è§„èŒƒçš„ä¸Šä¸‹æ–‡åˆ†ææŠ€èƒ½å®ç°
ç¬¦åˆ Claude å®˜æ–¹ Skills è§„èŒƒ
"""
import json
import re
from typing import Dict, Any


def execute_skill(event: Dict[str, Any], context: Any = None) -> Dict[str, Any]:
    """
    Claude Skills æ ‡å‡†æ‰§è¡Œå‡½æ•°
    """
    try:
        # ä»äº‹ä»¶ä¸­æå–å‚æ•°
        context_input = event.get('context') or event.get('input') or event.get('query', '')
        
        if not context_input.strip():
            error_result = {
                "success": False,
                "error": "Context input is required",
                "input": context_input
            }
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json'},
                'body': json.dumps(error_result)
            }

        # ç®€å•çš„ä¸Šä¸‹æ–‡åˆ†æï¼ˆåœ¨å®é™…å®ç°ä¸­ä¼šè°ƒç”¨AIæ¨¡å‹ï¼‰
        context_length = len(context_input)
        token_count_estimate = max(1, len(context_input) // 4)
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        clarity = min(1.0, max(0.0, 0.5 + len(context_input) * 0.00001))
        relevance = min(1.0, max(0.0, 0.7 + (0.1 if any(kw in context_input.lower() for kw in ['system', 'function', 'task', 'requirement']) else 0)))
        completeness = min(1.0, max(0.0, 0.3 + (0.3 if any(kw in context_input.lower() for kw in ['constraint', 'requirement', 'goal']) else 0)))
        consistency = min(1.0, max(0.0, 0.8 - (0.2 if any(kw in context_input.lower() for kw in ['but', 'however']) else 0)))
        efficiency = min(1.0, max(0.0, 1.0 - len(context_input) * 0.00005))

        result_data = {
            "context_length": context_length,
            "token_count_estimate": token_count_estimate,
            "metrics": {
                "clarity": round(clarity, 2),
                "relevance": round(relevance, 2),
                "completeness": round(completeness, 2),
                "consistency": round(consistency, 2),
                "efficiency": round(efficiency, 2)
            },
            "suggestions": [
                "Add more specific goal descriptions",
                "Supplement constraint conditions and specific requirements",
                "Improve expression clarity"
            ],
            "issues": [i for i in [
                "Lack of explicit constraint conditions" if completeness < 0.6 else "",
                "Some expressions can be more precise" if clarity < 0.7 else ""
            ] if i],  # Filter out empty issues
            "confidence": 0.85
        }

        success_result = {
            "success": True,
            "result": result_data,
            "input": context_input
        }
        
        return {
            'statusCode': 200,
            'headers': {'Content-Type': 'application/json'},
            'body': json.dumps(success_result)
        }
        
    except Exception as e:
        error_result = {
            'success': False,
            'error': str(e),
            'input': event
        }
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json'},
            'body': json.dumps(error_result)
        }


def lambda_handler(event: Dict[str, Any], context: Any = None) -> Dict[str, Any]:
    """
    AWS Lambda å…¼å®¹çš„å¤„ç†å‡½æ•°
    """
    return execute_skill(event, context)


# åŒæ—¶ä¿ç•™ DNASPEC æ ¼å¼çš„ execute å‡½æ•°ä»¥ä¿æŒå…¼å®¹æ€§
def execute(args: Dict[str, Any]) -> str:
    """
    DNASPEC æ ¼å¼çš„æ‰§è¡Œå‡½æ•°
    """
    context_input = args.get("context", args.get("description", args.get("input", "")))
    
    if not context_input.strip():
        return json.dumps({
            'success': False,
            'error': 'Context input is required',
            'result': None
        }, ensure_ascii=False)

    # æ‰§è¡Œåˆ†æé€»è¾‘
    context_length = len(context_input)
    token_count_estimate = max(1, len(context_input) // 4)
    
    # è®¡ç®—è´¨é‡æŒ‡æ ‡
    clarity = min(1.0, max(0.0, 0.5 + len(context_input) * 0.00001))
    relevance = min(1.0, max(0.0, 0.7 + (0.1 if any(kw in context_input.lower() for kw in ['system', 'function', 'task', 'requirement']) else 0)))
    completeness = min(1.0, max(0.0, 0.3 + (0.3 if any(kw in context_input.lower() for kw in ['constraint', 'requirement', 'goal']) else 0)))
    consistency = min(1.0, max(0.0, 0.8 - (0.2 if any(kw in context_input.lower() for kw in ['but', 'however']) else 0)))
    efficiency = min(1.0, max(0.0, 1.0 - len(context_input) * 0.00005))

    result_data = {
        "context_length": context_length,
        "token_count_estimate": token_count_estimate,
        "metrics": {
            "clarity": round(clarity, 2),
            "relevance": round(relevance, 2),
            "completeness": round(completeness, 2),
            "consistency": round(consistency, 2),
            "efficiency": round(efficiency, 2)
        },
        "suggestions": [
            "Add more specific goal descriptions",
            "Supplement constraint conditions and specific requirements", 
            "Improve expression clarity"
        ],
        "issues": [i for i in [
            "Lack of explicit constraint conditions" if completeness < 0.6 else "",
            "Some expressions can be more precise" if clarity < 0.7 else ""
        ] if i],  # Filter out empty issues
        "confidence": 0.85
    }

    # è¿”å›æ ¼å¼åŒ–çš„åˆ†æç»“æœ
    output_lines = []
    output_lines.append("Context Quality Analysis Results:")
    output_lines.append(f"Length: {result_data['context_length']} characters")
    output_lines.append(f"Token Estimate: {result_data['token_count_estimate']}")
    output_lines.append("")

    output_lines.append("Five-Dimensional Quality Metrics (0.0-1.0):")
    metric_names = {
        'clarity': 'Clarity', 'relevance': 'Relevance', 'completeness': 'Completeness',
        'consistency': 'Consistency', 'efficiency': 'Efficiency'
    }

    for metric, score in result_data['metrics'].items():
        indicator = "ğŸŸ¢" if score >= 0.7 else "ğŸŸ¡" if score >= 0.4 else "ğŸ”´"
        output_lines.append(f"  {indicator} {metric_names.get(metric, metric)}: {score:.2f}")

    if result_data.get('suggestions'):
        output_lines.append("\nOptimization Suggestions:")
        for s in result_data['suggestions'][:3]:  # Show top 3 suggestions
            output_lines.append(f"  â€¢ {s}")

    if result_data.get('issues'):
        output_lines.append("\nIdentified Issues:")
        for i in result_data['issues']:
            output_lines.append(f"  â€¢ {i}")

    return "\n".join(output_lines)